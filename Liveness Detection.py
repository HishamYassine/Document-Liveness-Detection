# -*- coding: utf-8 -*-
"""Global Features - threshold change.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MVUmk5kmAIRwcF5ne6uByc5iKbAdcY8c
"""

import os
import shutil
import random
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import cv2 
import pickle

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

from sklearn.metrics import r2_score, confusion_matrix
import mahotas

dataset= r'C:\Users\OS\Desktop\Capstone Project\Dataset\Dataset\1 fake sample'
labels = os.listdir(dataset)
x_image = []
y_label = []

for l in labels:
     category = os.path.join(dataset, l)
     for file in os.listdir(category):
        img = os.path.join(category, file)
        image = cv2.imread(img)
        image_resized = cv2.resize(image, (256,256))
       
        image_gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)
        
        
        # HUMoments for shape
        image_hu = cv2.HuMoments(cv2.moments(image_gray)).flatten()
# Haralick for texture 
        
        image_har = mahotas.features.haralick(image).mean(axis=0)
         # convert the image to HSV color-space
        image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
# color histogram
        image_hist  = cv2.calcHist([image_hsv], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
        cv2.normalize(image_hist, image_hist)
        image_hist_flat = image_hist.flatten()
# combine the features extracted
        f_vector_concat = np.hstack([image_hist_flat, image_har, image_hu])
        x_image.append(f_vector_concat)
        y_label.append(l)
        continue
     continue
     break

# convert lists to numpy array
x_image_n = np.array(x_image)
y_label_n = np.array(y_label)

# feature scaling between 0-1 
scaler = MinMaxScaler(feature_range=(0, 1))
x_image_scaled = scaler.fit_transform(x_image_n)

Liveness = {'Fake':0, 'Live':1}
y_label_le= np.vectorize(Liveness.get)(y_label_n)
print (y_label_le)

x_train, x_test, y_train, y_test = train_test_split(x_image_scaled, y_label_le, test_size=0.2, random_state=0)

clf_rfc = RandomForestClassifier().fit(x_train, y_train)

threshold = 0.72
y_pred_rfc = (clf_rfc.predict_proba(x_test)[:, 1] > threshold).astype('float')

#y_pred_rfc = clf_rfc.predict(x_test)
print("Accuracy: ",accuracy_score(y_test, y_pred_rfc))

print("Precision: ",precision_score(y_test, y_pred_rfc, average='weighted', labels=np.unique(y_pred_rfc)))
print("F1 Score: ",f1_score(y_test, y_pred_rfc, average='weighted', labels=np.unique(y_pred_rfc)))

tpr = recall_score(y_test, y_pred_rfc, pos_label = 1)
tnr= recall_score(y_test, y_pred_rfc, pos_label = 0)
print("Recall Score: ", tpr)


print("\n\nConfusion Matrix: ",confusion_matrix(y_test, y_pred_rfc))

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_rfc))

fpr = 1 - tnr
fnr = 1 - tpr
print("FAR: ", fpr*100,"%")
print("FRR: ", fnr*100,"%")

pickle.dump(clf_rfc, open(r'C:\Users\OS\Desktop\rfc_model', 'wb'))